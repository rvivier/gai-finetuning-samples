{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce8dce64-fc24-448c-bb4c-6dbb95d0bf55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install docker-compose --quiet\n",
    "!pip install unzip --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc08d62d-9d80-42d3-8574-878aef818468",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69f44d2-9b02-4cf4-ba92-ecf23e7e8b8b",
   "metadata": {},
   "source": [
    "The dataset we're using is a BBC news dataset that can be downloaded here:\n",
    "\n",
    "https://www.kaggle.com/datasets/pariza/bbc-news-summary?resource=download\n",
    "\n",
    "This dataset for extractive text summarization has four hundred and seventeen political news articles of BBC from 2004 to 2005 in the News Articles folder. For each articles, five summaries are provided in the Summaries folder. The first clause of the text of articles is the respective title. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce46706-d169-4f79-81a4-bc489ad48710",
   "metadata": {},
   "source": [
    "## Upload dataset zip file to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c94092f-417c-488a-9bfb-3bb7c3121bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::327216439222:role/Sagemaker\n",
      "sagemaker bucket: sagemaker-us-east-1-327216439222\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sess.boto_region_name\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sagemaker_session_bucket}\")\n",
    "print(f\"sagemaker session region: {region}\")\n",
    "\n",
    "filename = \"BBC_news_summary.zip\"\n",
    "s3_prefix = \"model-fine-tuning-data\"\n",
    "path_to_file = os.path.join(os.getcwd(), \"data\", filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eca1ed00-7166-4fd7-bcf7-5de4cc3fd15d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-327216439222/model-fine-tuning-data/BBC_news_summary.zip\n"
     ]
    }
   ],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "s3_client.upload_file(path_to_file, sagemaker_session_bucket, os.path.join(s3_prefix, filename))\n",
    "\n",
    "#S3 location with the BBC news data\n",
    "training_data_s3 = os.path.join(\"s3://\", sagemaker_session_bucket, s3_prefix, filename)\n",
    "print(training_data_s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec5c484-7378-49a1-9f4c-d47b78eea49a",
   "metadata": {},
   "source": [
    "{\n",
    "  \"id\": \"13818513\",\n",
    "  \"summary\": \"Amanda baked cookies and will bring Jerry some tomorrow.\",\n",
    "  \"dialogue\": \"Amanda: I baked cookies. Do you want some?\\r\\nJerry: Sure!\\r\\nAmanda: I'll bring you tomorrow :-)\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c88f559-f9a5-43cc-a484-b670cc3fad3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pipelines.finetuning_pipeline import get_pipeline\n",
    "\n",
    "#model group, pipeline and job names\n",
    "model_package_group_name = \"FineTunedModels\"\n",
    "pipeline_name = \"FineTunedModelsPipeline\"\n",
    "base_job_prefix=\"FineTunedModelsJob\"\n",
    "\n",
    "# These variables were defined the IAM role.\n",
    "pipeline = get_pipeline(\n",
    "    training_data_s3,\n",
    "    region=region,\n",
    "    role=role,\n",
    "    default_bucket=sagemaker_session_bucket,\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    pipeline_name=pipeline_name,\n",
    "    base_job_prefix=base_job_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79f141fc-f38c-41ff-a9e1-1ed6b5d3082e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'FineTunedModelsPipeline'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#register the pipeline\n",
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b497ab2-7665-437a-b329-4de38827b373",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting execution for pipeline FineTunedModelsPipeline. Execution ID is ffc42ff8-7208-4a9a-8080-51f32a50c480\n",
      "Starting pipeline step: 'FineTunedModelsProcess'\n",
      "Creating tyki8fsdyn-algo-1-vyq4v ... \n",
      "Creating tyki8fsdyn-algo-1-vyq4v ... done\n",
      "Attaching to tyki8fsdyn-algo-1-vyq4v\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m Collecting huggingface-hub==0.15.1 (from -r /opt/ml/processing/input/code/dataset_preparation/requirements.txt (line 1))\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m   Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m \u001b[?25hCollecting transformers==4.30.2 (from -r /opt/ml/processing/input/code/dataset_preparation/requirements.txt (line 2))\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m   Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m \u001b[?25hCollecting filelock (from huggingface-hub==0.15.1->-r /opt/ml/processing/input/code/dataset_preparation/requirements.txt (line 1))\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m   Downloading filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m Collecting fsspec (from huggingface-hub==0.15.1->-r /opt/ml/processing/input/code/dataset_preparation/requirements.txt (line 1))\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m   Downloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m \u001b[?25hRequirement already satisfied: requests in /miniconda3/lib/python3.8/site-packages (from huggingface-hub==0.15.1->-r /opt/ml/processing/input/code/dataset_preparation/requirements.txt (line 1)) (2.29.0)\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m Collecting tqdm>=4.42.1 (from huggingface-hub==0.15.1->-r /opt/ml/processing/input/code/dataset_preparation/requirements.txt (line 1))\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m   Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m \u001b[?25hCollecting pyyaml>=5.1 (from huggingface-hub==0.15.1->-r /opt/ml/processing/input/code/dataset_preparation/requirements.txt (line 1))\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m   Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.2/701.2 kB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m \u001b[?25hCollecting typing-extensions>=3.7.4.3 (from huggingface-hub==0.15.1->-r /opt/ml/processing/input/code/dataset_preparation/requirements.txt (line 1))\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m   Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m Collecting packaging>=20.9 (from huggingface-hub==0.15.1->-r /opt/ml/processing/input/code/dataset_preparation/requirements.txt (line 1))\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m   Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m \u001b[?25hRequirement already satisfied: numpy>=1.17 in /miniconda3/lib/python3.8/site-packages (from transformers==4.30.2->-r /opt/ml/processing/input/code/dataset_preparation/requirements.txt (line 2)) (1.24.1)\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m Collecting regex!=2019.12.17 (from transformers==4.30.2->-r /opt/ml/processing/input/code/dataset_preparation/requirements.txt (line 2))\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m   Downloading regex-2023.6.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.3/772.3 kB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m \u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30.2->-r /opt/ml/processing/input/code/dataset_preparation/requirements.txt (line 2))\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m   Downloading tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m:--:--\u001b[0m\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m \u001b[?25hCollecting safetensors>=0.3.1 (from transformers==4.30.2->-r /opt/ml/processing/input/code/dataset_preparation/requirements.txt (line 2))\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m   Downloading safetensors-0.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m \u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /miniconda3/lib/python3.8/site-packages (from requests->huggingface-hub==0.15.1->-r /opt/ml/processing/input/code/dataset_preparation/requirements.txt (line 1)) (2.0.4)\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m Requirement already satisfied: idna<4,>=2.5 in /miniconda3/lib/python3.8/site-packages (from requests->huggingface-hub==0.15.1->-r /opt/ml/processing/input/code/dataset_preparation/requirements.txt (line 1)) (3.4)\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m Requirement already satisfied: urllib3<1.27,>=1.21.1 in /miniconda3/lib/python3.8/site-packages (from requests->huggingface-hub==0.15.1->-r /opt/ml/processing/input/code/dataset_preparation/requirements.txt (line 1)) (1.26.15)\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /miniconda3/lib/python3.8/site-packages (from requests->huggingface-hub==0.15.1->-r /opt/ml/processing/input/code/dataset_preparation/requirements.txt (line 1)) (2022.12.7)\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m Installing collected packages: tokenizers, safetensors, typing-extensions, tqdm, regex, pyyaml, packaging, fsspec, filelock, huggingface-hub, transformers\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m Successfully installed filelock-3.12.2 fsspec-2023.6.0 huggingface-hub-0.15.1 packaging-23.1 pyyaml-6.0 regex-2023.6.3 safetensors-0.3.1 tokenizers-0.13.3 tqdm-4.65.0 transformers-4.30.2 typing-extensions-4.7.1\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m Starting preprocessing.\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m Downloading data from bucket: sagemaker-us-east-1-327216439222, key: model-fine-tuning-data/BBC_news_summary.zip\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m Unzipping downloaded data.\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v |\u001b[0m skipping:sport_199 due to UnicodeDecodeError\n",
      "\u001b[36mtyki8fsdyn-algo-1-vyq4v exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n",
      "Pipeline step 'FineTunedModelsProcess' SUCCEEDED.\n",
      "Pipeline execution ffc42ff8-7208-4a9a-8080-51f32a50c480 SUCCEEDED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CreationTime': 1688800264.312161,\n",
       " 'LastModifiedTime': 1688800276.708361,\n",
       " 'PipelineArn': 'FineTunedModelsPipeline',\n",
       " 'PipelineExecutionArn': 'ffc42ff8-7208-4a9a-8080-51f32a50c480',\n",
       " 'PipelineExecutionStatus': 'Succeeded'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execution = pipeline.start(\n",
    "    parameters=dict(\n",
    "        ModelApprovalStatus=\"Approved\", #PendingManualApproval\n",
    "    )\n",
    ")\n",
    "\n",
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c200df1-126e-40f1-8a9c-acbe8580cbb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5251916-5251-4d55-822e-e3377ef57294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900e21f7-dd0c-41d4-9461-79bc1910cabb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c672b6-1e72-4bd7-a24c-299a9cf430b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea955dd-2380-418d-8f88-fa009ef3ef3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23920427-fc5b-4451-94b3-0ad1b80e4833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1106b577-3cfd-4d25-9e81-f55a7d781c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152fc28b-5949-4242-9c2f-cbb4ececa105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3e754f-d7b8-4617-acb1-d64720fb5d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbc9b2d-427f-4b3d-8cc2-c046e5449c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
